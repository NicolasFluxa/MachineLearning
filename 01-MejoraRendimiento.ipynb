{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:42.024243Z",
     "start_time": "2026-01-20T19:34:42.011654Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Reducción_Memoria import reduce_mem_usage\n",
    "from Control_de_Daños import control_de_danos\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import json\n",
    "\n",
    "import joblib"
   ],
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:42.035268Z",
     "start_time": "2026-01-20T19:34:42.030500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "COLS_TARGET_ENC = ['trip_origin_city', 'trip_destination_city', 'pos', 'rt_cc', 'trip_rt'] # , 'pos', 'rt_group'\n",
    "COLS_ONE_HOT = ['trip_type', 'rt_group']\n",
    "\n",
    "SEED = 42\n",
    "TEST_SIZE_GENERAL = 0.1\n",
    "TEST_SIZE_PAIS = 0.1\n",
    "DATA_DIR = 'Data/'"
   ],
   "id": "ea4776bdd1ca42de",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:42.048077Z",
     "start_time": "2026-01-20T19:34:42.040232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CITY_TO_COUNTRY = {\n",
    "    # --- CHILE (CL) ---\n",
    "    'SCL': 'CL', 'ANF': 'CL', 'ARI': 'CL', 'BBA': 'CL', 'CCP': 'CL',\n",
    "    'CJC': 'CL', 'IQQ': 'CL', 'LSC': 'CL', 'PMC': 'CL', 'ZCO': 'CL',\n",
    "\n",
    "    # --- ARGENTINA (AR) ---\n",
    "    'EZE': 'AR', 'AEP': 'AR', 'BUE': 'AR',\n",
    "    'BRC': 'AR', 'COR': 'AR', 'CPC': 'AR', 'CRD': 'AR', 'FTE': 'AR',\n",
    "    'IGR': 'AR', 'MDZ': 'AR', 'NQN': 'AR', 'REL': 'AR', 'RES': 'AR',\n",
    "    'SLA': 'AR', 'TUC': 'AR', 'USH': 'AR',\n",
    "\n",
    "    # --- COLOMBIA (CO) ---\n",
    "    'BOG': 'CO', 'MDE': 'CO', 'CTG': 'CO', 'CLO': 'CO', 'ADZ': 'CO',\n",
    "    'BAQ': 'CO', 'CUC': 'CO', 'MTR': 'CO', 'PEI': 'CO', 'SMR': 'CO',\n",
    "\n",
    "    # --- PERÚ (PE) ---\n",
    "    'LIM': 'PE', 'AQP': 'PE', 'CUZ': 'PE', 'PIU': 'PE', 'TRU': 'PE',\n",
    "    'CIX': 'PE', 'CJA': 'PE', 'TPP': 'PE',\n",
    "\n",
    "    # --- BRASIL (BR) ---\n",
    "    'FLN': 'BR', 'IGU': 'BR', 'REC': 'BR', 'RIO': 'BR', 'SAO': 'BR',\n",
    "\n",
    "    # --- OTROS ---\n",
    "    'ASU': 'PY', # Paraguay\n",
    "    'MVD': 'UY', # Uruguay\n",
    "    'UIO': 'EC', # Ecuador\n",
    "    # Agrego US por seguridad (aunque no salgan en tu lista de origen, el POS existe)\n",
    "    'MIA': 'US', 'FLL': 'US', 'JFK': 'US'\n",
    "}"
   ],
   "id": "c9335349511fcb93",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:42.060735Z",
     "start_time": "2026-01-20T19:34:42.053864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def exportar_target_encoding_a_json(X_train, y_train, columnas_a_codificar, ruta_salida):\n",
    "    \"\"\"\n",
    "    Genera un diccionario con los mappings de Target Encoding por columna y lo guarda en JSON.\n",
    "    Estructura resultante:\n",
    "    {\n",
    "      \"global_mean\": 0.1234,\n",
    "      \"columns\": {\n",
    "        \"col1\": { \"mapping\": { \"catA\": 0.12, \"catB\": null }, \"else\": 0.1234 },\n",
    "        ...\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    temp_df = X_train.copy()\n",
    "    temp_df['target'] = y_train\n",
    "    global_mean = float(y_train.mean())\n",
    "\n",
    "    result = {'global_mean': global_mean, 'columns': {}}\n",
    "\n",
    "    for col in columnas_a_codificar:\n",
    "        mapping = temp_df.groupby(col, observed=False)['target'].mean()\n",
    "        col_map = {}\n",
    "        for categoria, valor in mapping.items():\n",
    "            # Normalizar clave para JSON (usar 'NULL' para NaNs)\n",
    "            key = 'NULL' if pd.isna(categoria) else str(categoria)\n",
    "            # Convertir valor a float o None si es NaN\n",
    "            val = None if pd.isna(valor) else float(valor)\n",
    "            col_map[key] = val\n",
    "\n",
    "        result['columns'][col] = {'mapping': col_map, 'else': global_mean}\n",
    "\n",
    "    # Guardar JSON\n",
    "    with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    return result"
   ],
   "id": "5951b2150619668",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:42.069054Z",
     "start_time": "2026-01-20T19:34:42.065442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def limpiar_moneda(serie):\n",
    "    \"\"\"\n",
    "    Convierte strings de moneda con formato '1.000,00' a float.\n",
    "    Si ya es numérico, lo devuelve tal cual (evita el error de los notebooks 03/04).\n",
    "    \"\"\"\n",
    "    if pd.api.types.is_numeric_dtype(serie):\n",
    "        return serie\n",
    "\n",
    "    # Convierte a string, quita puntos de mil, cambia coma por punto\n",
    "    clean = serie.astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
    "    return pd.to_numeric(clean, errors='coerce').fillna(0)\n"
   ],
   "id": "7b256d6d4c05ae97",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:42.083786Z",
     "start_time": "2026-01-20T19:34:42.074194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preparacion_maestra(df_input):\n",
    "    df = df_input.copy()\n",
    "\n",
    "    # 1. Imputación de Nulos Lógicos\n",
    "    cols_zero = ['length_of_stay', 'has_weekends', 'working_days']\n",
    "    for col in cols_zero:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(0)\n",
    "\n",
    "    # 2. Limpieza de Monedas\n",
    "    cols_dinero = ['ancillary_revenue', 'fare_revenue']\n",
    "    for col in cols_dinero:\n",
    "        if col in df.columns:\n",
    "            df[col] = limpiar_moneda(df[col])\n",
    "\n",
    "    # 3. Creación del TARGET (Regla de Negocio)\n",
    "    if 'motivo_de_viaje' in df.columns:\n",
    "        mapa = {'Trabajo': 1, 'Vacaciones': 0, 'Familiar': 0}\n",
    "        df['target'] = df['motivo_de_viaje'].map(mapa)\n",
    "\n",
    "    # 4. Creamos columna que relaciona 'pos' con 'rt_group', si compra en chile para volar fuera es ocio\n",
    "    def obtener_pais_vuelo(row):\n",
    "        grupo = str(row['rt_group'])\n",
    "\n",
    "        # Caso 1: Vuelo Doméstico (DOMCO, DOMPE, DOMAR...)\n",
    "        if grupo.startswith('DOM'):\n",
    "            return grupo[-2:] # Retorna CO, PE, AR, CL\n",
    "\n",
    "        # Caso 2: Vuelo Internacional (INTER)\n",
    "        # Miramos el origen. Si sale de LIM es vuelo \"Peruano\" en origen.\n",
    "        orig = row['trip_origin_city']\n",
    "        return CITY_TO_COUNTRY.get(orig, 'OTRO')\n",
    "\n",
    "\n",
    "    if all(c in df.columns for c in ['has_bag', 'has_pb', 'has_seat']):\n",
    "        df['perfil_ejecutivo_ligero'] = (\n",
    "            (df['has_bag'] == 0) &\n",
    "            ((df['has_pb'] == 1) | (df['has_seat'] == 1))\n",
    "        ).astype(int)\n",
    "    else:\n",
    "        df['perfil_ejecutivo_ligero'] = 0\n",
    "\n",
    "    # Solo aplica si NO es Solo Ida (trip_type=2)\n",
    "    df['es_viaje_corto'] = (\n",
    "        (df['trip_type'] == 2) &          # Condición 1: Que sea Ida y Vuelta\n",
    "        (df['length_of_stay'] <= 2) &     # Condición 2: Max 2 días\n",
    "        (df['length_of_stay'] > 0)        # Condición 3: Que no sea 0 (por seguridad)\n",
    "    ).astype(int)\n",
    "\n",
    "    # 7. Ingeniería de Fechas (Cíclicas)\n",
    "    if 'trip_start_date' in df.columns:\n",
    "        fechas = pd.to_datetime(df['trip_start_date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "        # Ciclo Mensual (1-12)\n",
    "        df['month_sin'] = np.sin(2 * np.pi * fechas.dt.month / 12)\n",
    "        df['month_cos'] = np.cos(2 * np.pi * fechas.dt.month / 12)\n",
    "\n",
    "        # Ciclo Semanal (0-6)\n",
    "        df['dow_sin'] = np.sin(2 * np.pi * fechas.dt.dayofweek / 7)\n",
    "        df['dow_cos'] = np.cos(2 * np.pi * fechas.dt.dayofweek / 7)\n",
    "\n",
    "        df.drop(columns=['trip_start_date'], inplace=True)\n",
    "\n",
    "    # 5. Eliminación de Columnas Ruidosas o Redundantes\n",
    "    cols_drop = ['has_promo_class', 'promocode', 'recordlocator','discounted_fare_revenue_dc', 'discounted_fare_revenue_pc', 'discount_perc', 'infants', 'children', 'status', 'booking_hour', 'booking_dow', 'booking_weeknumber', 'booking_weeknumber', 'bookingid', 'working_days', 'weekend_days', 'booking_date', 'trip_end_dow', 'motivo_de_viaje', 'total_revenue', 'channel'] # , 'has_ins', 'has_pb', 'has_flex'\n",
    "\n",
    "    df.drop(columns=[c for c in cols_drop if c in df.columns], inplace=True, errors='ignore')\n",
    "    print(f\"Columnas eliminadas: {len(cols_drop)}\")\n",
    "\n",
    "\n",
    "    return df"
   ],
   "id": "af41cba5740f183b",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:42.215629Z",
     "start_time": "2026-01-20T19:34:42.087888Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('DataSet.csv', sep=';')",
   "id": "b43ac5669a85630e",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:42.251107Z",
     "start_time": "2026-01-20T19:34:42.223006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# B. Control de Daños (Tu función original)\n",
    "control_de_danos(df)\n"
   ],
   "id": "a804bdbbe1199c04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porcentaje de NaN por columna:\n",
      "                            Total_values  NaN_values  Completeness  \\\n",
      "promocode                          30428       28325          2103   \n",
      "has_weekends                       30428       14643         15785   \n",
      "length_of_stay                     30428       14636         15792   \n",
      "trip_end_dow                       30428       14636         15792   \n",
      "working_days                       30428       14636         15792   \n",
      "weekend_days                       30428       14636         15792   \n",
      "bookingid                          30428           0         30428   \n",
      "recordlocator                      30428           0         30428   \n",
      "booking_dow                        30428           0         30428   \n",
      "booking_hour                       30428           0         30428   \n",
      "motivo_de_viaje                    30428           0         30428   \n",
      "pos                                30428           0         30428   \n",
      "rt_group                           30428           0         30428   \n",
      "channel                            30428           0         30428   \n",
      "booking_date                       30428           0         30428   \n",
      "booking_weeknumber                 30428           0         30428   \n",
      "trip_destination_city              30428           0         30428   \n",
      "trip_origin_city                   30428           0         30428   \n",
      "trip_rt                            30428           0         30428   \n",
      "rt_cc                              30428           0         30428   \n",
      "days_to_departure                  30428           0         30428   \n",
      "status                             30428           0         30428   \n",
      "trip_type                          30428           0         30428   \n",
      "trip_start_dow                     30428           0         30428   \n",
      "trip_start_date                    30428           0         30428   \n",
      "paxs                               30428           0         30428   \n",
      "children                           30428           0         30428   \n",
      "adults                             30428           0         30428   \n",
      "infants                            30428           0         30428   \n",
      "has_chd_inf                        30428           0         30428   \n",
      "has_promocode                      30428           0         30428   \n",
      "has_promo_class                    30428           0         30428   \n",
      "has_promo                          30428           0         30428   \n",
      "total_revenue                      30428           0         30428   \n",
      "fare_revenue                       30428           0         30428   \n",
      "ancillary_revenue                  30428           0         30428   \n",
      "discounted_fare_revenue_dc         30428           0         30428   \n",
      "discounted_fare_revenue_pc         30428           0         30428   \n",
      "discount_perc                      30428           0         30428   \n",
      "has_discount                       30428           0         30428   \n",
      "has_bundle                         30428           0         30428   \n",
      "has_bag                            30428           0         30428   \n",
      "has_carry                          30428           0         30428   \n",
      "has_seat                           30428           0         30428   \n",
      "has_flex                           30428           0         30428   \n",
      "has_pb                             30428           0         30428   \n",
      "has_ins                            30428           0         30428   \n",
      "has_ptc                            30428           0         30428   \n",
      "\n",
      "                            missing_pct  \n",
      "promocode                       93.0886  \n",
      "has_weekends                    48.1234  \n",
      "length_of_stay                  48.1004  \n",
      "trip_end_dow                    48.1004  \n",
      "working_days                    48.1004  \n",
      "weekend_days                    48.1004  \n",
      "bookingid                        0.0000  \n",
      "recordlocator                    0.0000  \n",
      "booking_dow                      0.0000  \n",
      "booking_hour                     0.0000  \n",
      "motivo_de_viaje                  0.0000  \n",
      "pos                              0.0000  \n",
      "rt_group                         0.0000  \n",
      "channel                          0.0000  \n",
      "booking_date                     0.0000  \n",
      "booking_weeknumber               0.0000  \n",
      "trip_destination_city            0.0000  \n",
      "trip_origin_city                 0.0000  \n",
      "trip_rt                          0.0000  \n",
      "rt_cc                            0.0000  \n",
      "days_to_departure                0.0000  \n",
      "status                           0.0000  \n",
      "trip_type                        0.0000  \n",
      "trip_start_dow                   0.0000  \n",
      "trip_start_date                  0.0000  \n",
      "paxs                             0.0000  \n",
      "children                         0.0000  \n",
      "adults                           0.0000  \n",
      "infants                          0.0000  \n",
      "has_chd_inf                      0.0000  \n",
      "has_promocode                    0.0000  \n",
      "has_promo_class                  0.0000  \n",
      "has_promo                        0.0000  \n",
      "total_revenue                    0.0000  \n",
      "fare_revenue                     0.0000  \n",
      "ancillary_revenue                0.0000  \n",
      "discounted_fare_revenue_dc       0.0000  \n",
      "discounted_fare_revenue_pc       0.0000  \n",
      "discount_perc                    0.0000  \n",
      "has_discount                     0.0000  \n",
      "has_bundle                       0.0000  \n",
      "has_bag                          0.0000  \n",
      "has_carry                        0.0000  \n",
      "has_seat                         0.0000  \n",
      "has_flex                         0.0000  \n",
      "has_pb                           0.0000  \n",
      "has_ins                          0.0000  \n",
      "has_ptc                          0.0000  \n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:42.484188Z",
     "start_time": "2026-01-20T19:34:42.264900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# C. Aplicar Preparación Maestra\n",
    "df_clean = preparacion_maestra(df)\n"
   ],
   "id": "bd0a7042b2fb104a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas eliminadas: 21\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:42.536467Z",
     "start_time": "2026-01-20T19:34:42.498076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# D. Reducción de Memoria Final\n",
    "control_de_danos(df_clean)\n",
    "df_clean = reduce_mem_usage(df_clean)\n"
   ],
   "id": "36ea84d4d9af160f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porcentaje de NaN por columna:\n",
      "                         Total_values  NaN_values  Completeness  missing_pct\n",
      "pos                             30428           0         30428          0.0\n",
      "rt_group                        30428           0         30428          0.0\n",
      "days_to_departure               30428           0         30428          0.0\n",
      "rt_cc                           30428           0         30428          0.0\n",
      "trip_rt                         30428           0         30428          0.0\n",
      "trip_origin_city                30428           0         30428          0.0\n",
      "trip_destination_city           30428           0         30428          0.0\n",
      "trip_type                       30428           0         30428          0.0\n",
      "length_of_stay                  30428           0         30428          0.0\n",
      "trip_start_dow                  30428           0         30428          0.0\n",
      "has_weekends                    30428           0         30428          0.0\n",
      "paxs                            30428           0         30428          0.0\n",
      "adults                          30428           0         30428          0.0\n",
      "has_chd_inf                     30428           0         30428          0.0\n",
      "has_promocode                   30428           0         30428          0.0\n",
      "has_promo                       30428           0         30428          0.0\n",
      "fare_revenue                    30428           0         30428          0.0\n",
      "ancillary_revenue               30428           0         30428          0.0\n",
      "has_discount                    30428           0         30428          0.0\n",
      "has_bundle                      30428           0         30428          0.0\n",
      "has_bag                         30428           0         30428          0.0\n",
      "has_carry                       30428           0         30428          0.0\n",
      "has_seat                        30428           0         30428          0.0\n",
      "has_flex                        30428           0         30428          0.0\n",
      "has_pb                          30428           0         30428          0.0\n",
      "has_ins                         30428           0         30428          0.0\n",
      "has_ptc                         30428           0         30428          0.0\n",
      "target                          30428           0         30428          0.0\n",
      "compra_extranjera               30428           0         30428          0.0\n",
      "perfil_ejecutivo_ligero         30428           0         30428          0.0\n",
      "es_viaje_corto                  30428           0         30428          0.0\n",
      "month_sin                       30428           0         30428          0.0\n",
      "month_cos                       30428           0         30428          0.0\n",
      "dow_sin                         30428           0         30428          0.0\n",
      "dow_cos                         30428           0         30428          0.0\n",
      "Memoria inicial: 8.13 MB\n",
      "Memoria final: 1.32 MB\n",
      "Reducción: 83.7%\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:42.736051Z",
     "start_time": "2026-01-20T19:34:42.542251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_clean_general = df_clean.copy()\n",
    "\n",
    "# Separar X e y ANTES de codificar\n",
    "X_general = df_clean_general.drop('target', axis=1)\n",
    "y_general = df_clean_general['target']\n",
    "\n",
    "# Dividir en train/test\n",
    "X_train_gen, X_test_gen, y_train_gen, y_test_gen = train_test_split(\n",
    "    X_general, y_general, test_size=TEST_SIZE_GENERAL, random_state=SEED, stratify=y_general\n",
    ")\n",
    "\n",
    "preprocessor_general = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target_encoder', ce.TargetEncoder(), COLS_TARGET_ENC),\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False), COLS_ONE_HOT)\n",
    "    ],\n",
    "    remainder='passthrough', # Mantiene las columnas no especificadas (numéricas)\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "# Ajustar el preprocesador SOLO con los datos de entrenamiento\n",
    "preprocessor_general.fit(X_train_gen, y_train_gen)\n",
    "\n",
    "# Transformar ambos conjuntos\n",
    "X_train_gen_encoded = preprocessor_general.transform(X_train_gen)\n",
    "X_test_gen_encoded = preprocessor_general.transform(X_test_gen)\n",
    "\n",
    "json_path = f'{DATA_DIR}target_encoding_gen.json'\n",
    "exportar_target_encoding_a_json(X_train_gen, y_train_gen, COLS_TARGET_ENC, json_path)\n",
    "\n",
    "# Guardar archivos\n",
    "X_train_gen_encoded.to_parquet(f'{DATA_DIR}X_train_general_encoded.parquet')\n",
    "X_test_gen_encoded.to_parquet(f'{DATA_DIR}X_test_general_encoded.parquet')\n",
    "y_train_gen.to_pickle(f'{DATA_DIR}y_train_general.pkl')\n",
    "y_test_gen.to_pickle(f'{DATA_DIR}y_test_general.pkl')\n",
    "joblib.dump(preprocessor_general, f'{DATA_DIR}preprocessor_general.pkl')"
   ],
   "id": "83bf1bddde959f7b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/preprocessor_general.pkl']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:43.133862Z",
     "start_time": "2026-01-20T19:34:42.751423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 2. PROCESAMIENTO PARA MODELOS POR PAÍS ---\n",
    "print(\"\\nProcesando y guardando para Modelos por País...\")\n",
    "paises = ['CL', 'AR', 'PE', 'CO'] # , 'INTER'\n",
    "\n",
    "for pais in paises:\n",
    "    df_pais = df_clean[df_clean['pos'] == pais].copy()\n",
    "    if df_pais.empty:\n",
    "        continue\n",
    "\n",
    "    print(f\"Procesando para: {pais}\")\n",
    "\n",
    "    # Columnas para este país (excluimos 'pos' ya que es constante)\n",
    "    cols_target_pais = [c for c in COLS_TARGET_ENC if c != 'pos']\n",
    "    cols_onehot_pais = COLS_ONE_HOT\n",
    "\n",
    "    X_pais = df_pais.drop(['target', 'pos'], axis=1)\n",
    "    y_pais = df_pais['target']\n",
    "\n",
    "    X_train_pais, X_test_pais, y_train_pais, y_test_pais = train_test_split(\n",
    "        X_pais, y_pais, test_size=TEST_SIZE_PAIS, random_state=SEED, stratify=y_pais\n",
    "    )\n",
    "\n",
    "    # Preprocesador específico para el país\n",
    "    preprocessor_pais = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('target_encoder', ce.TargetEncoder(), cols_target_pais),\n",
    "            ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cols_onehot_pais)\n",
    "        ],\n",
    "        remainder='passthrough',\n",
    "        verbose_feature_names_out=False\n",
    "    ).set_output(transform=\"pandas\")\n",
    "\n",
    "    # Ajustar y transformar\n",
    "    preprocessor_pais.fit(X_train_pais, y_train_pais)\n",
    "    X_train_pais_encoded = preprocessor_pais.transform(X_train_pais)\n",
    "    X_test_pais_encoded = preprocessor_pais.transform(X_test_pais)\n",
    "\n",
    "    json_path = f'DiccTargetEncoder/target_encoding_{pais}.json'\n",
    "\n",
    "    exportar_target_encoding_a_json(X_train_pais, y_train_pais, cols_target_pais, json_path)\n",
    "\n",
    "\n",
    "    # Guardar archivos\n",
    "    X_train_pais_encoded.to_parquet(f'{DATA_DIR}X_train_{pais}_encoded.parquet')\n",
    "    X_test_pais_encoded.to_parquet(f'{DATA_DIR}X_test_{pais}_encoded.parquet')\n",
    "    y_train_pais.to_pickle(f'{DATA_DIR}y_train_{pais}.pkl')\n",
    "    y_test_pais.to_pickle(f'{DATA_DIR}y_test_{pais}.pkl')\n",
    "    joblib.dump(preprocessor_pais, f'{DATA_DIR}preprocessor_{pais}.pkl')\n"
   ],
   "id": "b6b7db8eff855cc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando y guardando para Modelos por País...\n",
      "Procesando para: CL\n",
      "Procesando para: AR\n",
      "Procesando para: PE\n",
      "Procesando para: CO\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:43.404609Z",
     "start_time": "2026-01-20T19:34:43.148615Z"
    }
   },
   "cell_type": "code",
   "source": "df_clean.to_csv(f'{DATA_DIR}df_full.csv', index=False, sep=';')",
   "id": "2558aac346072237",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T19:34:43.461321Z",
     "start_time": "2026-01-20T19:34:43.421175Z"
    }
   },
   "cell_type": "code",
   "source": "df_clean.to_parquet(f'{DATA_DIR}df_full.parquet')",
   "id": "c8867fae5dedce48",
   "outputs": [],
   "execution_count": 99
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
